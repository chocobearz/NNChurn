---
title: "Correlation plot"
author: "Paige, Vicky, and Jackie"
date: '2019-11-10'
output: 
  prettydoc::html_pretty:
  theme : cayman
  highlight : github
  math: katex
---

# Loading libraries
```{r}
library(ggplot2)
library(reshape2) # Used for the melt function
library(dplyr)
library(forcats) # Used in the correlation plot for fct_rev
```

#load data

```{r}
cd <- read.csv(file = "cleanData.csv", header = TRUE, sep = ",", 
                stringsAsFactors = T)

print("ORIGIN DATA")

summary(cd)
```

# Correlation ratio function
```{r}
cor_ratio <- function(column1, column2){
    # Some assumptions
    # This function assumes no NA's, and that the rows of both columns are
    # in correct orders
    
    # If the order of the column classes are factor first, then use
    # the same function but swap the columns
    if(class(column1) == "factor" & 
       (class(column2) == "numeric" | class(column2) == "integer")){
        cor_ratio(column2, column1)
    }
    # If the columns types are in the correct order
    else if( (class(column1) == "numeric" | class(column1) == "integer") &
        class(column2) == "factor"){
            # Create a temporary dataframe to store columns for filter function
            temp_df <- data.frame("score" = column1,
                                  "subject" = column2)
            
            # Create a dataframe to store sum of squares of category
            # observation minus the category mean
            ss_df <- expand.grid( "factors" = levels(factor(column2)),
                                    "ss" = 0)
            for( i in c(1:length( levels(factor(column2)) )) ){
                subset <- filter(temp_df, 
                                 subject == levels(factor(column2))[i] )
                subset_mean <- mean(subset[ , 1])
                sum_value = sum((subset[ , 1] - subset_mean)^2)
                ss_df$ss[i] <- sum_value
            }
            # Remove variables that are no longer needed
            rm(subset, subset_mean, sum_value)
            
            # Assigning variables for these sums of squares for debugging
            ss1 <- sum(ss_df$ss)
            ss2 <- sum( (temp_df$score - mean(temp_df$score))^2 )
            
            correlation_value <- sqrt( (ss2 - sum(ss_df$ss)) / ss2)
            
            # Removing variables that are no longer needed
            rm(temp_df, ss1, ss2)
            
            return(correlation_value)
        }
    else{ # Error message if the incorrect inputs are given
        return("Error! This function only accepts one vector of class 'numeric'
               and one vector of class 'factor'.")
    }
}

# Wikipedia example
# https://en.wikipedia.org/wiki/Correlation_ratio

# SS1 values
# 1952 for algebra
# 308 for geometry
# 600 for statistics
# adds up to 2860

# SS2 should be 9640

# Correlation should be 0.8386

df2 <- data.frame(score = c(45, 70, 29, 15, 21, 40, 20, 30, 42, 65, 95, 80, 70, 85, 73), 
                  subject = c(rep("Algebra", times = 5),
                              rep("Geometry", times = 4),
                              rep("Statistics", times = 6)
                              )
                  )

# Also testing that the ordering if/else statements are working
cor_ratio(df2$score, df2$subject)
cor_ratio(df2$subject, df2$score)

# Removing example variable
rm(df2)
```

# Getting correlations
```{r}
# Method used to get 'correlation' for categorical variables
# https://datascience.stackexchange.com/questions/893/how-to-get-correlation-between-two-categorical-variable-and-a-categorical-variab#898

# All column types in cd are either factors (categorical), 
# or numerical (including integers)
unlist(lapply(cd, class))

# Calculate correlation for dataframe with categorical and numerical variables
categorical_cor <- function(column1, column2){
    if( class(column1) == "factor" &&
        (class(column2) == "numeric" || class(column2) == "integer")
    ){  # Swap the columns; I think this is having issues, I will just try
        # call the function again, but with swapped columns
        # temp_column = column1
        # column1 = column2
        # column2 = temp_column
        # rm(temp_column)
        categorical_cor(column2, column1)
    } # Columns should be numerical/integer, then factor
    # else if(column1 == column2){
    #     # Hard coding a correlation of 1 if both columns are the same
    #     return(1)
    # }
    else{
        if( # Use chi squared if class(column) == factor for both
            (class(column1) == "factor") &&
            (class(column2) == "factor")
        ){
            # Not sure if correct needs to be equal to F, 
            # but the link shows it
            
            # https://www.r-bloggers.com/example-8-39-calculating-cramers-v/
            cramers_v = sqrt(chisq.test(column1, column2, 
                                        correct = F)$statistic / 
                                 (length(column1) * 
                                      ( min(length(unique(column1)), 
                                           length(unique(column2))) - 1 )))
            return(as.numeric(cramers_v))
            #return(chisq.test(column1, column2, correct = F)$p.value)
        }
        else if( # Use corr if class(column) == numerical or integer for both
            ( (class(column1) == "numeric") ||
            (class(column1) == "integer") ) &&
            ( (class(column2) == "numeric") ||
            (class(column2) == "integer") )
        ){
            cor(column1, column2)
        }
        else if( # Use the p-value from aov if the columns are a mix
            (class(column1) == "numeric" || class(column1) == "integer") &&
            class(column2) == "factor"
        ){
            # Get a correlation ratio for mixed columns
            return(cor_ratio(column1, column2))
        }
        else{ # Return this message if at least one of the columns
            # is a different class than factor, numerical or integer
            return("error, 
                   class(column) must be factor, numerical, or integer")
        }
    }
}

# Create an empty data frame to store all the correlation values
cd.cor <- cbind(expand.grid("Column_1" = colnames(cd), 
                            "Column_2" = colnames(cd)), "Corr" = 0)
# Add the correlation values
# Find a way to fill the "Corr" column with values from the custom function

```

# Create correlation plot matrix
```{r}
head(cd.cor$Column_1)

# For each row of cd.cor

# Use the function on two columns; the column names are obtained from
# the first two columns of cd.cor

for(i in c(1:529)){
    cd.cor[i, 3] <- categorical_cor(cd[[ cd.cor[i, 1] ]], 
                                    cd[[ cd.cor[i, 2] ]])
    
}

# Link to code involving the chi-squared test code
# https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test
# Link to explanation of formula
# https://www.spss-tutorials.com/cramers-v-what-and-why/

# Pearson's chi-squared test (Ï‡2) is a statistical test applied to sets of 
# categorical data to evaluate how likely it is that any observed 
# difference between the sets arose by chance
```


Heatmap
```{r}
# Heatmap code from the link below
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
ggplot(data = cd.cor.long, aes(x = Column_1, y = fct_rev(factor(Column_2)), 
                          fill = Corr)) +
    geom_tile(color = "black") +
    scale_fill_gradient2(low = "#1a0033", high = "white", mid = "#d90048",
                         midpoint = 0.5, limit = c(0, 1), space = "Lab",
                         name = "Correlation") +
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
    coord_fixed() +
    xlab("Variable 1") +
    ylab("Variable 2")
```

Exact correlation values
```{r}
# Churn correlation values
filter(cd.cor, Column_1 == "churn") %>% arrange(desc(Corr))

```





